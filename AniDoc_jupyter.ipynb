{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/AniDoc-jupyter/blob/main/AniDoc_jupyter.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjYy0F2gZIPR"
   },
   "outputs": [],
   "source": [
    "# !pip install torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 torchtext==0.18.0 torchdata==0.8.0 --extra-index-url https://download.pytorch.org/whl/cu124\n",
    "# !pip install xformers==0.0.28.post3\n",
    "!apt install aria2 -qqy\n",
    "\n",
    "%cd /content\n",
    "!git clone https://github.com/yihao-meng/AniDoc\n",
    "%cd /content/AniDoc\n",
    "\n",
    "!pip install diffusers==0.24.0 transformers==4.27.0 accelerate huggingface_hub==0.24.7\n",
    "!pip install opencv-contrib-python imageio imageio-ffmpeg ffmpeg-python av moviepy==1.0.3\n",
    "!pip install kornia einops scikit-image omegaconf colorlog pyparsing==3.0.9 matplotlib git+https://github.com/XPixelGroup/BasicSR\n",
    "\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/stable-video-diffusion-img2vid/raw/main/feature_extractor/preprocessor_config.json -d /content/AniDoc/pretrained_weights/stable-video-diffusion-img2vid-xt/feature_extractor -o preprocessor_config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/stable-video-diffusion-img2vid/raw/main/image_encoder/config.json -d /content/AniDoc/pretrained_weights/stable-video-diffusion-img2vid-xt/image_encoder -o config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/stable-video-diffusion-img2vid/resolve/main/image_encoder/model.fp16.safetensors -d /content/AniDoc/pretrained_weights/stable-video-diffusion-img2vid-xt/image_encoder -o model.fp16.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/stable-video-diffusion-img2vid/raw/main/scheduler/scheduler_config.json -d /content/AniDoc/pretrained_weights/stable-video-diffusion-img2vid-xt/scheduler -o scheduler_config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/stable-video-diffusion-img2vid/raw/main/unet/config.json -d /content/AniDoc/pretrained_weights/stable-video-diffusion-img2vid-xt/unet -o config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/stable-video-diffusion-img2vid/resolve/main/unet/diffusion_pytorch_model.fp16.safetensors -d /content/AniDoc/pretrained_weights/stable-video-diffusion-img2vid-xt/unet -o diffusion_pytorch_model.fp16.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/stable-video-diffusion-img2vid/raw/main/vae/config.json -d /content/AniDoc/pretrained_weights/stable-video-diffusion-img2vid-xt/vae -o config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/stable-video-diffusion-img2vid/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors -d /content/AniDoc/pretrained_weights/stable-video-diffusion-img2vid-xt/vae -o diffusion_pytorch_model.fp16.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/stable-video-diffusion-img2vid/raw/main/model_index.json -d /content/AniDoc/pretrained_weights/stable-video-diffusion-img2vid-xt -o model_index.json\n",
    "\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Yhmeng1106/anidoc/resolve/main/anidoc/scheduler.bin -d /content/AniDoc/pretrained_weights/anidoc -o scheduler.bin \n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Yhmeng1106/anidoc/resolve/main/anidoc/scaler.pt -d /content/AniDoc/pretrained_weights/anidoc -o scaler.pt \n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Yhmeng1106/anidoc/resolve/main/anidoc/random_states_0.pkl -d /content/AniDoc/pretrained_weights/anidoc -o random_states_0.pkl \n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Yhmeng1106/anidoc/raw/main/anidoc/unet/config.json -d /content/AniDoc/pretrained_weights/anidoc/unet -o config.json \n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Yhmeng1106/anidoc/resolve/main/anidoc/unet/diffusion_pytorch_model.safetensors -d /content/AniDoc/pretrained_weights/anidoc/unet -o diffusion_pytorch_model.safetensors \n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Yhmeng1106/anidoc/raw/main/anidoc/controlnet/config.json -d /content/AniDoc/pretrained_weights/anidoc/controlnet -o config.json \n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Yhmeng1106/anidoc/resolve/main/anidoc/controlnet/diffusion_pytorch_model.safetensors -d /content/AniDoc/pretrained_weights/anidoc/controlnet -o diffusion_pytorch_model.safetensors\n",
    "\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/cotracker/resolve/main/cotracker2.pth -d /content/AniDoc/pretrained_weights -o cotracker2.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/AniDoc\n",
    "!CUDA_VISIBLE_DEVICES=0 python scripts_infer/anidoc_inference.py --all_sketch --matching --tracking --control_image 'data_test/sample1.mp4' --ref_image 'data_test/sample1.png' --output_dir 'results' --max_point 10"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
